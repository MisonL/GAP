# 导入类型注解相关的模块
# Import modules related to type annotations
from typing import List, Dict, Optional, Union, Literal, Any # 导入 Any 类型 (Import Any type)
# 导入 Pydantic 用于数据验证和模型定义
# Import Pydantic for data validation and model definition
from pydantic import BaseModel, Field # 导入 BaseModel 和 Field (Import BaseModel and Field)

# 定义聊天消息的模型，用于表示单条聊天记录，与 OpenAI API 兼容
# Define the model for chat messages, used to represent a single chat record, compatible with OpenAI API
class Message(BaseModel):
    """
    表示聊天消息的结构。
    Represents the structure of a chat message.
    """
    role: str  # 消息发送者的角色 (例如 "user", "assistant", "system") (The role of the message sender (e.g., "user", "assistant", "system"))
    content: Union[str, List[Dict]]  # 消息内容。可以是纯文本字符串，也可以是包含多部分（如文本和图像）的字典列表，以支持多模态输入。 (The content of the message. Can be a plain text string or a list of dictionaries containing multiple parts (e.g., text and images) to support multimodal input.)

# 定义模型响应消息的模型，用于表示模型生成的单条消息，可能包含工具调用
# Define the model for model response messages, used to represent a single message generated by the model, potentially including tool calls
class ResponseMessage(BaseModel):
    """
    表示模型响应消息的结构，可能包含工具调用。
    Represents the structure of a model response message, potentially including tool calls.
    """
    role: str # 消息发送者的角色，对于响应消息通常是 "assistant" (The role of the message sender, typically "assistant" for response messages)
    content: Optional[str] = None # 响应内容，对于纯工具调用可能为 None (The response content, may be None for pure tool calls)
    tool_calls: Optional[List[Dict[str, Any]]] = None # 模型请求的工具调用列表 (List of tool calls requested by the model)


# 定义聊天补全请求的模型，包含了调用模型所需的所有参数，与 OpenAI API 兼容
# Define the model for chat completion requests, containing all parameters required to call the model, compatible with OpenAI API
class ChatCompletionRequest(BaseModel):
    """
    表示聊天补全请求的结构。
    Represents the structure of a chat completion request.
    """
    model: str  # 要使用的模型名称 (The name of the model to use)
    messages: List[Message]  # 包含聊天历史的消息列表 (A list of messages comprising the conversation history)
    temperature: float = 0.7  # 控制生成文本的随机性，值越高越随机 (Controls the randomness of the generated text, higher values are more random)
    top_p: Optional[float] = 1.0  # 控制核心采样的概率阈值 (Controls the probability threshold for nucleus sampling)
    n: int = 1  # 为每个输入消息生成多少个聊天补全选项 (目前代理只支持 1) (How many chat completion choices to generate for each input message (currently the proxy only supports 1))
    stream: bool = False  # 是否以流式方式返回响应 (Whether to return the response in a streaming manner)
    stop: Optional[Union[str, List[str]]] = None  # 指定停止生成的序列 (Specifies sequences that stop the generation)
    max_tokens: Optional[int] = None  # 限制生成的最大 token 数量 (Limits the maximum number of tokens to generate)
    presence_penalty: Optional[float] = 0.0  # 对新出现 token 的惩罚因子 (Penalty factor for new tokens)
    frequency_penalty: Optional[float] = 0.0  # 对已出现 token 的惩罚因子 (Penalty factor for tokens that have already appeared)

# 定义聊天补全响应中的单个选项模型
# Define the model for a single choice in a chat completion response
class Choice(BaseModel):
    """
    表示聊天补全响应中的一个选项。
    Represents a choice in a chat completion response.
    """
    index: int  # 选项的索引 (通常为 0) (The index of the choice (usually 0))
    message: ResponseMessage  # 模型生成的消息内容，使用 ResponseMessage 以支持工具调用 (The message content generated by the model, using ResponseMessage to support tool calls)
    finish_reason: Optional[str] = None  # 生成停止的原因 (例如 "stop", "length", "safety") (The reason the generation stopped (e.g., "stop", "length", "safety"))

# 定义 API 调用中 token 使用情况的模型
# Define the model for token usage in an API call
class Usage(BaseModel):
    """
    表示 API 调用中的 token 使用情况。
    Represents token usage in an API call.
    """
    prompt_tokens: int = 0  # 输入提示的 token 数量 (The number of tokens in the input prompt)
    completion_tokens: int = 0  # 生成内容的 token 数量 (The number of tokens in the generated content)
    total_tokens: int = 0  # 总 token 数量 (The total number of tokens)

# 定义聊天补全响应的整体模型，包含了所有返回信息，与 OpenAI API 兼容
# Define the overall model for a chat completion response, containing all returned information, compatible with OpenAI API
class ChatCompletionResponse(BaseModel):
    """
    表示聊天补全响应的整体结构。
    Represents the overall structure of a chat completion response.
    """
    id: str  # 响应的唯一标识符 (目前为固定值) (The unique identifier for the response (currently a fixed value))
    object: Literal["chat.completion"]  # 对象类型，固定为 "chat.completion" (The object type, fixed as "chat.completion")
    created: int  # 响应创建的时间戳 (目前为固定值) (The timestamp when the response was created (currently a fixed value))
    model: str  # 使用的模型名称 (The name of the model used)
    choices: List[Choice]  # 包含生成结果的选项列表 (A list of choices containing the generated results)
    usage: Usage = Field(default_factory=Usage)  # Token 使用情况，如果未提供则使用默认工厂创建 (Token usage, if not provided, a default factory is used to create it)

# 定义 API 错误响应的模型
# Define the model for API error responses
class ErrorResponse(BaseModel):
    """
    表示 API 错误响应的结构。
    Represents the structure of an API error response.
    """
    message: str  # 错误信息 (The error message)
    type: str  # 错误类型 (例如 "invalid_request_error", "internal_error") (The error type (e.g., "invalid_request_error", "internal_error"))
    param: Optional[str] = None  # 导致错误的参数 (如果适用) (The parameter that caused the error (if applicable))
    code: Optional[str] = None  # 错误代码 (如果适用) (The error code (if applicable))

# 定义获取可用模型列表的响应模型
# Define the response model for getting the list of available models
class ModelList(BaseModel):
    """
    表示模型列表响应的结构。
    Represents the structure of a model list response.
    """
    object: str = "list"  # 对象类型，固定为 "list" (The object type, fixed as "list")
    data: List[Dict]  # 包含模型信息的字典列表 (A list of dictionaries containing model information)
