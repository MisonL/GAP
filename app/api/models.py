# 导入类型注解相关的模块
# Import modules related to type annotations
from typing import List, Dict, Optional, Union, Literal, Any # 导入 Any 类型 (Import Any type)
# 导入 Pydantic 用于数据验证和模型定义
# Import Pydantic for data validation and model definition
from pydantic import BaseModel, Field # 导入 BaseModel 和 Field (Import BaseModel and Field)

# 定义聊天消息的模型，用于表示单条聊天记录，与 OpenAI API 兼容
# Define the model for chat messages, used to represent a single chat record, compatible with OpenAI API
class Message(BaseModel):
    """
    表示聊天消息的结构。
    Represents the structure of a chat message.
    """
    role: str  # 消息发送者的角色 (例如 "user", "assistant", "system") (The role of the message sender (e.g., "user", "assistant", "system"))
    content: Union[str, List[Dict]]  # 消息内容。可以是纯文本字符串，也可以是包含多部分（如文本和图像）的字典列表，以支持多模态输入。 (The content of the message. Can be a plain text string or a list of dictionaries containing multiple parts (e.g., text and images) to support multimodal input.)

# 定义模型响应消息的模型，用于表示模型生成的单条消息，可能包含工具调用
# Define the model for model response messages, used to represent a single message generated by the model, potentially including tool calls
class ResponseMessage(BaseModel):
    """
    表示模型响应消息的结构，可能包含工具调用。
    Represents the structure of a model response message, potentially including tool calls.
    """
    role: str # 消息发送者的角色，对于响应消息通常是 "assistant" (The role of the message sender, typically "assistant" for response messages)
    content: Optional[str] = None # 响应内容，对于纯工具调用可能为 None (The response content, may be None for pure tool calls)
    tool_calls: Optional[List[Dict[str, Any]]] = None # 模型请求的工具调用列表 (List of tool calls requested by the model)


# 定义聊天补全请求的模型，包含了调用模型所需的所有参数，与 OpenAI API 兼容
# Define the model for chat completion requests, containing all parameters required to call the model, compatible with OpenAI API
class ChatCompletionRequest(BaseModel):
    """
    表示聊天补全请求的结构。
    Represents the structure of a chat completion request.
    """
    model: str  # 要使用的模型名称 (The name of the model to use)
    messages: List[Message]  # 包含聊天历史的消息列表 (A list of messages comprising the conversation history)
    temperature: float = 0.7  # 控制生成文本的随机性，值越高越随机 (Controls the randomness of the generated text, higher values are more random)
    top_p: Optional[float] = 1.0  # 控制核心采样的概率阈值 (Controls the probability threshold for nucleus sampling)
    n: int = 1  # 为每个输入消息生成多少个聊天补全选项 (目前代理只支持 1) (How many chat completion choices to generate for each input message (currently the proxy only supports 1))
    stream: bool = False  # 是否以流式方式返回响应 (Whether to return the response in a streaming manner)
    stop: Optional[Union[str, List[str]]] = None  # 指定停止生成的序列 (Specifies sequences that stop the generation)
    max_tokens: Optional[int] = None  # 限制生成的最大 token 数量 (Limits the maximum number of tokens to generate)
    presence_penalty: Optional[float] = 0.0  # 对新出现 token 的惩罚因子 (Penalty factor for new tokens)
    frequency_penalty: Optional[float] = 0.0  # 对已出现 token 的惩罚因子 (Penalty factor for tokens that have already appeared)

# 定义聊天补全响应中的单个选项模型
# Define the model for a single choice in a chat completion response
class Choice(BaseModel):
    """
    表示聊天补全响应中的一个选项。
    Represents a choice in a chat completion response.
    """
    index: int  # 选项的索引 (通常为 0) (The index of the choice (usually 0))
    message: ResponseMessage  # 模型生成的消息内容，使用 ResponseMessage 以支持工具调用 (The message content generated by the model, using ResponseMessage to support tool calls)
    finish_reason: Optional[str] = None  # 生成停止的原因 (例如 "stop", "length", "safety") (The reason the generation stopped (e.g., "stop", "length", "safety"))

# 定义 API 调用中 token 使用情况的模型
# Define the model for token usage in an API call
class Usage(BaseModel):
    """
    表示 API 调用中的 token 使用情况。
    Represents token usage in an API call.
    """
    prompt_tokens: int = 0  # 输入提示的 token 数量 (The number of tokens in the input prompt)
    completion_tokens: int = 0  # 生成内容的 token 数量 (The number of tokens in the generated content)
    total_tokens: int = 0  # 总 token 数量 (The total number of tokens)

# 定义聊天补全响应的整体模型，包含了所有返回信息，与 OpenAI API 兼容
# Define the overall model for a chat completion response, containing all returned information, compatible with OpenAI API
class ChatCompletionResponse(BaseModel):
    """
    表示聊天补全响应的整体结构。
    Represents the overall structure of a chat completion response.
    """
    id: str  # 响应的唯一标识符 (目前为固定值) (The unique identifier for the response (currently a fixed value))
    object: Literal["chat.completion"]  # 对象类型，固定为 "chat.completion" (The object type, fixed as "chat.completion")
    created: int  # 响应创建的时间戳 (目前为固定值) (The timestamp when the response was created (currently a fixed value))
    model: str  # 使用的模型名称 (The name of the model used)
    choices: List[Choice]  # 包含生成结果的选项列表 (A list of choices containing the generated results)
    usage: Usage = Field(default_factory=Usage)  # Token 使用情况，如果未提供则使用默认工厂创建 (Token usage, if not provided, a default factory is used to create it)

# 定义 API 错误响应的模型
# Define the model for API error responses
class ErrorResponse(BaseModel):
    """
    表示 API 错误响应的结构。
    Represents the structure of an API error response.
    """
    message: str  # 错误信息 (The error message)
    type: str  # 错误类型 (例如 "invalid_request_error", "internal_error") (The error type (e.g., "invalid_request_error", "internal_error"))
    param: Optional[str] = None  # 导致错误的参数 (如果适用) (The parameter that caused the error (if applicable))
    code: Optional[str] = None  # 错误代码 (如果适用) (The error code (if applicable))

# 定义获取可用模型列表的响应模型
# Define the response model for getting the list of available models
class ModelList(BaseModel):
    """
    表示模型列表响应的结构。
    Represents the structure of a model list response.
    """
    object: str = "list"  # 对象类型，固定为 "list" (The object type, fixed as "list")
    data: List[Dict]  # 包含模型信息的字典列表 (A list of dictionaries containing model information)

# --- Gemini 原生 API (v2) 模型 ---
# --- Gemini Native API (v2) Models ---

class GeminiContentPart(BaseModel):
    """
    表示 Gemini 内容中的一个部分 (例如文本或内嵌数据)。
    Represents a part within Gemini content (e.g., text or inline data).
    """
    text: Optional[str] = None # 文本内容 (Text content)
    # TODO: 未来可能需要添加对 inline_data (图像等) 的支持
    # TODO: May need to add support for inline_data (images, etc.) in the future
    # inline_data: Optional[Dict[str, Any]] = None # 内嵌数据 (Inline data)

class GeminiContent(BaseModel):
    """
    表示 Gemini 对话中的一段内容，包含角色和多个部分。
    Represents a piece of content in a Gemini conversation, containing a role and multiple parts.
    """
    role: str # 内容的角色 (例如 "user", "model") (The role of the content (e.g., "user", "model"))
    parts: List[GeminiContentPart] # 内容的各个部分 (List of parts comprising the content)

class GeminiGenerationConfig(BaseModel):
    """
    表示 Gemini 生成内容的配置参数。
    Represents configuration parameters for Gemini content generation.
    """
    temperature: Optional[float] = Field(None, ge=0.0, le=2.0) # 控制随机性 (Controls randomness)
    top_p: Optional[float] = Field(None, ge=0.0, le=1.0) # 控制核心采样 (Controls nucleus sampling)
    top_k: Optional[int] = Field(None, ge=1) # 控制 Top-K 采样 (Controls Top-K sampling)
    candidate_count: Optional[int] = Field(None, ge=1) # 生成的候选数量 (Number of candidates to generate)
    max_output_tokens: Optional[int] = Field(None, ge=1) # 最大输出 token 数量 (Maximum number of output tokens)
    stop_sequences: Optional[List[str]] = None # 停止生成的序列 (Sequences that stop generation)

class GeminiSafetySetting(BaseModel):
    """
    表示 Gemini 安全设置，用于指定某个类别的阈值。
    Represents Gemini safety settings, specifying thresholds for a category.
    """
    category: str # 安全类别 (例如 "HARM_CATEGORY_HARASSMENT") (Safety category)
    threshold: str # 阈值 (例如 "BLOCK_MEDIUM_AND_ABOVE") (Threshold)

class GeminiSafetyRating(BaseModel):
    """
    表示 Gemini 安全评分，用于指示某个类别的风险概率。
    Represents Gemini safety rating, indicating risk probability for a category.
    """
    category: str # 安全类别 (Safety category)
    probability: str # 风险概率 (Risk probability)
    blocked: Optional[bool] = None # 是否被阻止 (Whether it was blocked)

class GeminiPromptFeedback(BaseModel):
    """
    表示 Gemini 对输入提示的反馈，例如安全评分。
    Represents Gemini's feedback on the input prompt, such as safety ratings.
    """
    safety_ratings: Optional[List[GeminiSafetyRating]] = None # 安全评分列表 (List of safety ratings)
    block_reason: Optional[str] = None # 阻止原因 (Block reason)

class GeminiCandidate(BaseModel):
    """
    表示 Gemini 生成的单个响应候选。
    Represents a single response candidate generated by Gemini.
    """
    content: GeminiContent # 候选内容 (Candidate content)
    finish_reason: Optional[str] = None # 生成停止的原因 (Reason generation stopped)
    safety_ratings: Optional[List[GeminiSafetyRating]] = None # 候选的安全评分 (Safety ratings for the candidate)
    citation_metadata: Optional[Dict[str, Any]] = None # 引用元数据 (Citation metadata)
    # TODO: 未来可能需要添加对 Grounding 信息的支持
    # TODO: May need to add support for Grounding information in the future
    # grounding_attributions: Optional[List[Dict[str, Any]]] = None # Grounding 归因 (Grounding attributions)

class GeminiGenerateContentRequestV2(BaseModel):
    """
    表示 Gemini /v2/models/{model}:generateContent 请求的结构。
    Represents the structure of a Gemini /v2/models/{model}:generateContent request.
    """
    contents: List[GeminiContent] # 对话内容列表 (List of conversation content)
    generation_config: Optional[GeminiGenerationConfig] = None # 生成配置 (Generation configuration)
    safety_settings: Optional[List[GeminiSafetySetting]] = None # 安全设置 (Safety settings)
    # TODO: 未来可能需要添加对 tools 和 tool_config 的支持
    # TODO: May need to add support for tools and tool_config in the future
    # tools: Optional[List[Dict[str, Any]]] = None # 工具定义 (Tool definitions)
    # tool_config: Optional[Dict[str, Any]] = None # 工具配置 (Tool configuration)

class GeminiGenerateContentResponseV2(BaseModel):
    """
    表示 Gemini /v2/models/{model}:generateContent 响应的结构。
    Represents the structure of a Gemini /v2/models/{model}:generateContent response.
    """
    candidates: List[GeminiCandidate] # 生成的候选列表 (List of generated candidates)
    prompt_feedback: Optional[GeminiPromptFeedback] = None # 对输入提示的反馈 (Feedback on the input prompt)
    usage_metadata: Optional[Dict[str, Any]] = None # 使用情况元数据 (Usage metadata)
    # TODO: 未来可能需要添加对 stream 响应的支持
    # TODO: May need to add support for streaming responses in the future
